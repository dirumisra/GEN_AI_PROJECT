{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strings (text)\n",
    "\n",
    "What a string is : Immutable sequence of Unicode code points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87299a2e",
   "metadata": {},
   "source": [
    "##### Essential creation & inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826ac96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable length is: > 18\n",
      "\n",
      "First Char of variable :> H\n",
      "nLast char of variable : > !\n",
      "llo, \n",
      "Reverse char of variable: > !sovnoChceT ,olleH\n"
     ]
    }
   ],
   "source": [
    "s = \"Hello, TechConvos!\"\n",
    "\n",
    "# length\n",
    "len(s)\n",
    "print(\"variable length is: >\", len(s))\n",
    "\n",
    "# indexing\n",
    "print(\"\\nFirst Char of variable :>\", s[0])\n",
    "print(\"nLast char of variable : >\", s[-1])\n",
    "\n",
    "# slicing, reverse\n",
    "# syntax of slicing Start:End:interval\n",
    "print(s[2:7])\n",
    "\n",
    "print(\"Reverse char of variable: >\",s[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594e7325",
   "metadata": {},
   "source": [
    "#### Trimming & normalizing whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0df0c941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ORIGINAL STRINGS ===\n",
      "\n",
      "name :>  'Dhiraj     Mishra'\n",
      "leftstrip ' Tech Convos'\n",
      "right_tstrip 'Tech Convos '\n",
      "\n",
      "===Space Count====\n",
      "Left spaces in 'name': 0\n",
      "Right spaces in 'name': 0\n",
      "Left spaces in 'leftstrip': 1\n",
      "Right spaces in 'right_strip': 1\n",
      "\n",
      "=== NORMALIZED NAME ===\n",
      "Original length: > 17\n",
      "Cleaned Length: > 13\n",
      "Cleaned output: > Dhiraj Mishra\n",
      "\n",
      "=== TRIMMED STRINGS ===\n",
      "Trimmed 'name': 'Dhiraj     Mishra'\n",
      "Trimmed 'leftstrip': 'Tech Convos'\n",
      "Trimmed 'right_strip': 'Tech Convos'\n",
      "\n",
      "=== STRINGS WITH PRESERVED PADDING ===\n",
      "Left-padded 'name': 'Dhiraj     Mishra'\n",
      "Right-padded 'name': 'Dhiraj     Mishra'\n",
      "Left-padded 'leftstrip': '  Tech Convos'\n",
      "Right-padded 'right_strip': 'Tech Convos  '\n"
     ]
    }
   ],
   "source": [
    "# STRING MANIPULATION & WHITESPACE HANDLING IN PYTHON\n",
    "# ----------------------------------------------\n",
    "# Define three strings with different spacing issues\n",
    "\n",
    "name = \"Dhiraj     Mishra\"        # This string has multiple spaces **between** the words.\n",
    "leftstrip = \" Tech Convos\"        # This string has one leading space at the beginning.\n",
    "right_strip = \"Tech Convos \"      # This string has one trailing space at the end.\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# STEP 1: CALCULATE LEADING AND TRAILING SPACES\n",
    "\n",
    "# Count how many spaces are on the **left side** (leading) of 'name'\n",
    "# len(name) gives total length, len(name.lstrip()) removes leading spaces\n",
    "left_space_name =  len(name) - len(name.lstrip())\n",
    "\n",
    "# Count how many spaces are on the **right side** (trailing) of 'name'\n",
    "right_space_name = len(name) - len(name.rstrip())\n",
    "\n",
    "# Repeat the same logic for 'leftstrip'\n",
    "lspace_leftstrip = len(leftstrip) - len(leftstrip.lstrip())\n",
    "\n",
    "# Repeat the same logic for 'righttstrip'\n",
    "\n",
    "rspace_rstrip = len(right_strip) - len(right_strip.rstrip())\n",
    "\n",
    "# PRINT ORIGINAL STRINGS (with repr to show hidden spaces)\n",
    "print(\"=== ORIGINAL STRINGS ===\\n\")\n",
    "print(\"name :> \", repr(name))           # repr() shows the string with quotes and visible spaces\n",
    "print(\"leftstrip\", repr(leftstrip))     # Useful for debugging leading/trailing whitespace\n",
    "print(\"right_tstrip\", repr(right_strip))\n",
    "\n",
    "# DISPLAY COUNT OF SPACES\n",
    "\n",
    "print(\"\\n===Space Count====\")\n",
    "print(\"Left spaces in 'name':\", left_space_name)\n",
    "print(\"Right spaces in 'name':\", right_space_name)\n",
    "\n",
    "print(\"Left spaces in 'leftstrip':\", lspace_leftstrip)\n",
    "print(\"Right spaces in 'right_strip':\", rspace_rstrip )\n",
    "\n",
    "\n",
    "# NORMALIZE 'name' (Collapse multiple spaces to a single space)\n",
    "# name.split() splits string into words (splits on ANY whitespace)\n",
    "# \" \".join(...) joins the words with **a single space**\n",
    "\n",
    "clean_name = \" \".join(name.split())\n",
    "\n",
    "print(\"\\n=== NORMALIZED NAME ===\")\n",
    "\n",
    "print(\"Original length: >\", len(name))\n",
    "print(\"Cleaned Length: >\", len(clean_name))\n",
    "print(\"Cleaned output: >\",clean_name)\n",
    "\n",
    "#  STRIP SPACES FROM STRINGS\n",
    "# .strip() removes spaces from both ends\n",
    "trimed_name = name.strip()\n",
    "\n",
    "\n",
    "# .strip() works the same for the other strings\n",
    "trimed_leftstrip = leftstrip.strip()\n",
    "trimed_rightstrip = right_strip.strip()\n",
    "\n",
    "\n",
    "print(\"\\n=== TRIMMED STRINGS ===\")\n",
    "print(\"Trimmed 'name':\", repr(trimed_name))               # No leading/trailing spaces\n",
    "print(\"Trimmed 'leftstrip':\", repr(trimed_leftstrip))     # Should remove 1 leading space\n",
    "print(\"Trimmed 'right_strip':\", repr(trimed_rightstrip))  # Should remove 1 trailing space\n",
    "\n",
    "# RECONSTRUCT STRINGS WITH PRESERVED PADDING\n",
    "\n",
    "# Recreate the left-padded version of 'name' by prepending the counted spaces\n",
    "\n",
    "left_padded_name = \" \" * left_space_name + name\n",
    "\n",
    "\n",
    "# Do the same for 'leftstrip' and 'right_strip'\n",
    "left_padded_leftstrip = \" \" * lspace_leftstrip + leftstrip\n",
    "right_padded_rightstrip = right_strip + \" \" * rspace_rstrip\n",
    "\n",
    "print(\"\\n=== STRINGS WITH PRESERVED PADDING ===\")\n",
    "print(\"Left-padded 'name':\", repr(left_padded_name))\n",
    "print(\"Right-padded 'name':\", repr(right_padded_name))\n",
    "print(\"Left-padded 'leftstrip':\", repr(left_padded_leftstrip))\n",
    "print(\"Right-padded 'right_strip':\", repr(right_padded_rightstrip))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee0076b",
   "metadata": {},
   "source": [
    "#### Splitting (your key request) & joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdb068b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'for', 'Data', '&', 'BI']\n"
     ]
    }
   ],
   "source": [
    "text = \"Python   for   Data   &   BI\"\n",
    "token = text.split()  # ['Python', 'for', 'Data', '&', 'BI']\n",
    "\n",
    "print(token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41aef51",
   "metadata": {},
   "source": [
    "#### Split on a specific delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "077acdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dhiraj', 'Mishra', 'Team Lead']\n",
      "C:\n",
      "olist_orders.csv\n",
      "['C:', 'Data', 'Raw', 'olist_orders.csv']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define the full file path as a string\n",
    "path = \"C:/Data/Raw/olist_orders.csv\"\n",
    "\n",
    "# Step 2: Split the path string at each \"/\" to separate the components\n",
    "# This will create a list of parts: drive letter, folders, and the filename\n",
    "paths = path.split(\"/\")   # Output: ['C:', 'Data', 'Raw', 'olist_orders.csv']\n",
    "\n",
    "# Step 3: Use unpacking to extract the first and last elements from the list\n",
    "# root      -> 'C:'        (the drive letter or root folder)\n",
    "# *_        -> ['Data', 'Raw'] (the middle folders, ignored here with _)\n",
    "# filename  -> 'olist_orders.csv' (the actual file name at the end of the path)\n",
    "root, *_, filename = paths\n",
    "\n",
    "# Step 4: Define a string that simulates a row of data, with fields separated by \"|\"\n",
    "row = \"Dhiraj|Mishra|Team Lead\"\n",
    "\n",
    "# Step 5: Split the row at the \"|\" symbol to get a list of individual fields\n",
    "# Output: ['Dhiraj', 'Mishra', 'Team Lead']\n",
    "# (Although you’re not storing the result here, this line splits the row)\n",
    "print(row.split(\"|\"))\n",
    "\n",
    "# Step 6: Print the extracted root (e.g., 'C:')\n",
    "print(root)\n",
    "\n",
    "# Step 7: Print the extracted filename (e.g., 'olist_orders.csv')\n",
    "print(filename)\n",
    "\n",
    "# Step 8: Print the full list of path parts\n",
    "# Output: ['C:', 'Data', 'Raw', 'olist_orders.csv']\n",
    "print(paths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c4131",
   "metadata": {},
   "source": [
    "#### Limit splits (performance & control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7be22934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=42\n",
      "name=Dhiraj;role=Team Lead;dept=BI\n"
     ]
    }
   ],
   "source": [
    "record = \"id=42;name=Dhiraj;role=Team Lead;dept=BI\"\n",
    "\n",
    "first, rest = record.split(\";\",1)  # split only once (left to right)\n",
    "\n",
    "\n",
    "# first: 'id=42', rest: 'name=Dhiraj;role=Team Lead;dept=BI'\n",
    "\n",
    "\n",
    "print(first)\n",
    "print(rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99000519",
   "metadata": {},
   "source": [
    "#### Right split (useful for filenames, trailing fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc079aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "report.2025.08.26.final\n",
      "csv\n"
     ]
    }
   ],
   "source": [
    "# Assign the filename as a string\n",
    "fname = \"report.2025.08.26.final.csv\"\n",
    "\n",
    "# Split the filename from the right at the last '.' to separate the extension\n",
    "# 'rsplit(\".\", 1)' means: split from the right, only once\n",
    "# This will return ['report.2025.08.26.final', 'csv']\n",
    "base, ext = fname.rsplit(\".\", 1)\n",
    "\n",
    "# Print the base part of the filename (everything before the last dot)\n",
    "print(base)\n",
    "print(ext)\n",
    "# Print the extension (everything after the last dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c109e",
   "metadata": {},
   "source": [
    "#### Lines handling (robust across OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13ca8946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line1\n",
      "line2\n",
      "line3\n"
     ]
    }
   ],
   "source": [
    "# Define a string with mixed newline characters (\\r\\n and \\n)\n",
    "doc = \"line1\\r\\nline2\\nline3\"\n",
    "\n",
    "# Split the string into lines, handling all newline types\n",
    "lines = doc.splitlines()\n",
    "\n",
    "# Print the original string (will display as 3 lines)\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c4c123",
   "metadata": {},
   "source": [
    "#### Re‑join tokens — the fast way to build strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ddfed85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python | Data | Fabric | Snowflake'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = [\"Python\", \"Data\", \"Fabric\", \"Snowflake\"]\n",
    "\" | \".join(words)              # 'Python | Data | Fabric | Snowflake'\n",
    "# Best approach: accumulate pieces in a list, ''.join(pieces) at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178fecba",
   "metadata": {},
   "source": [
    "#### Searching & replacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "172225fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Fabric with Python and Snowflake\n"
     ]
    }
   ],
   "source": [
    "# Assign a string to the variable 's'\n",
    "s = \"Power BI with Python and Snowflake\"\n",
    "\n",
    "# Find the index of the first occurrence of the character 'i'\n",
    "# Returns the index (0-based), or -1 if not found\n",
    "search_output = s.find('i')\n",
    "\n",
    "# Print the index where 'i' first appears in the string\n",
    "print(search_output)\n",
    "\n",
    "# Replace the substring \"Power BI\" with \"Fabric\" in 's'\n",
    "# This returns a new string; 's' itself is not modified\n",
    "replace_output = s.replace(\"Power BI\", \"Fabric\")\n",
    "\n",
    "# Print the modified string\n",
    "print(replace_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e249d15e",
   "metadata": {},
   "source": [
    "#### Case handling (for normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "76702a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original str : >  USER@EXAMPLE.COM\n",
      "Lowercase email: user@example.com\n",
      "Lowered: straße\n",
      "Casefolded: strasse\n"
     ]
    }
   ],
   "source": [
    "# Original email string in uppercase\n",
    "email = \"USER@EXAMPLE.COM\"\n",
    "\n",
    "# Convert the email to lowercase using .lower()\n",
    "# This is useful for case-insensitive comparisons or deduplication (e.g. treating 'User@Example.com' and 'user@example.com' as the same)\n",
    "email_lower = email.lower()\n",
    "\n",
    "# Print the normalized lowercase email\n",
    "print(\"original str : > \", email)\n",
    "print(\"Lowercase email:\", email_lower)  # Output: user@example.com\n",
    "\n",
    "# --- International Case Handling Example ---\n",
    "\n",
    "# Suppose we are working with a string containing international characters\n",
    "# For example, the German letter \"ß\" (sharp S) which should be treated like \"ss\" in comparisons\n",
    "german_word = \"straße\"\n",
    "\n",
    "# Using .lower() — basic lowercase conversion (won't change ß)\n",
    "lowered = german_word.lower()\n",
    "\n",
    "# Using .casefold() — more aggressive and Unicode-aware\n",
    "# It converts ß → ss, which is more appropriate for case-insensitive comparisons in some languages\n",
    "folded = german_word.casefold()\n",
    "\n",
    "# Print results to show the difference\n",
    "print(\"Lowered:\", lowered)    # Output: straße\n",
    "print(\"Casefolded:\", folded)  # Output: strasse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858c4cfc",
   "metadata": {},
   "source": [
    "#### Formatting (f‑strings: best approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "371068c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DHIRAJ - TEAM LEAD @ MASTEK 2025\n"
     ]
    }
   ],
   "source": [
    "# Assign the user's name to a variable\n",
    "user = 'dhiraj'\n",
    "\n",
    "# Assign the user's role to a variable\n",
    "role = 'team lead'\n",
    "\n",
    "# Assign the year to a variable\n",
    "year = 2025\n",
    "\n",
    "# Convert 'Mastek' to uppercase using .upper()\n",
    "msg = f\"{user.upper()} - {role.upper()} @ {'Mastek'.upper()} {year}\"\n",
    "\n",
    "# Print the final message\n",
    "print(msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fa9371",
   "metadata": {},
   "source": [
    "#### Validation & parsing (digits, alpha, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba3c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# --- isdigit() ---\n",
    "# Only digits → returns True\n",
    "print(\"12345\".isdigit())    # True\n",
    "\n",
    "# Contains a letter → returns False\n",
    "print(\"123a5\".isdigit())    # False\n",
    "\n",
    "\n",
    "# --- isalpha() ---\n",
    "# Only letters → returns True\n",
    "print(\"abcXYZ\".isalpha())   # True\n",
    "\n",
    "# Contains a number → returns False\n",
    "print(\"abc123\".isalpha())   # False\n",
    "\n",
    "# --- isalnum() ---\n",
    "# Letters and numbers only → returns True\n",
    "print(\"abc123\".isalnum())   # True\n",
    "\n",
    "# Contains a space → returns False\n",
    "print(\"abc 123\".isalnum())  # False\n",
    "\n",
    "\n",
    "# --- isspace() ---\n",
    "# Only spaces → returns True\n",
    "print(\"   \".isspace())      # True\n",
    "\n",
    "# Contains a tab and a letter → returns False\n",
    "print(\" \\ta\".isspace())     # False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fb23b",
   "metadata": {},
   "source": [
    "#### Cleaning data (ETL‑style string scenarios)\n",
    "\n",
    "_A) Normalize names (spaces, case, punctuation)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b83f0292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dhiraj Mishra\n",
      "John Doe\n",
      "Alice O'Connor\n",
      "Elon Musk\n",
      "Mary Anne\n"
     ]
    }
   ],
   "source": [
    "def normalize_name(raw: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize user-entered names:\n",
    "    - Remove leading/trailing/multiple spaces\n",
    "    - Fix inconsistent capitalization (e.g., dHiRaJ -> Dhiraj)\n",
    "    Steps:\n",
    "    1. raw.split() breaks the string into words, removing extra spaces\n",
    "    2. \" \".join(...) joins words back with single spaces\n",
    "    3. .title() capitalizes the first letter of each word\n",
    "    \"\"\"\n",
    "    core = \" \".join(raw.split())     # Remove extra/multiple spaces\n",
    "    return core.title()              # Capitalize each word correctly\n",
    "\n",
    "\n",
    "# Example inputs (messy names)\n",
    "name1 = \"   dHiRaJ   mIsHrA   \"\n",
    "name2 = \"JOHN    doe\"\n",
    "name3 = \"  alice   o'connor  \"\n",
    "name4 = \"eLon    MUsK\"\n",
    "name5 = \"  mAry     AnnE  \"\n",
    "\n",
    "# Normalize each name using the function\n",
    "print(normalize_name(name1))  # Output: Dhiraj Mishra\n",
    "print(normalize_name(name2))  # Output: John Doe\n",
    "print(normalize_name(name3))  # Output: Alice O'Connor\n",
    "print(normalize_name(name4))  # Output: Elon Musk\n",
    "print(normalize_name(name5))  # Output: Mary Anne\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988db0b2",
   "metadata": {},
   "source": [
    "_B) Extract domain from email_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c1ea6ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example.com\n",
      "None\n",
      "None\n",
      "sub.domain.com\n",
      "example.co.uk\n"
     ]
    }
   ],
   "source": [
    "def email_domain(email: str) -> str | None:\n",
    "    email = email.strip()                      # Remove leading/trailing spaces\n",
    "    if '@' not in email or email.count(\"@\") != 1:  # Check for exactly one '@'\n",
    "        return None                            # Return None if invalid email\n",
    "    _, domain = email.rsplit(\"@\", 1)           # Split from right at '@' to get domain\n",
    "    return domain.lower()                       # Return domain in lowercase\n",
    "\n",
    "# Test cases to check the function behavior\n",
    "print(email_domain(\" User@Example.COM \"))   # Output: example.com (valid email)\n",
    "print(email_domain(\"no-at-symbol\"))          # Output: None (missing '@')\n",
    "print(email_domain(\"wrong@@example.com\"))    # Output: None (more than one '@')\n",
    "print(email_domain(\"admin@Sub.Domain.COM\"))  # Output: sub.domain.com (valid email)\n",
    "print(email_domain(\"   alice@Example.co.uk \"))  # Output: example.co.uk (valid email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c27d01a",
   "metadata": {},
   "source": [
    "_C) Robust CSV line split (when fields may contain commas)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e6cb9466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'age', 'city']\n",
      "['Alice', '30', 'New York']\n",
      "['Bob', '25', 'Los Angeles']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "line = \"name,age,city\\nAlice,30,New York\\nBob,25,Los Angeles\"  # CSV data in a string\n",
    "\n",
    "reader = csv.reader(StringIO(line))  # Convert string to file-like object, then parse CSV\n",
    "\n",
    "for row in reader:\n",
    "    print(row)  # Prints each row as a list of values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9150dcaa",
   "metadata": {},
   "source": [
    "_D) File path utilities (use pathlib, best approach)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee5d3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "olist_orders.csv\n",
      "olist_orders\n",
      ".csv\n",
      "C:\\Data\\Raw\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path  # Import Path class from pathlib module\n",
    "\n",
    "p = Path(r\"C:\\Data\\Raw\\olist_orders.csv\")  # Create a Path object representing the file path\n",
    "\n",
    "print(p.name)    # 'olist_orders.csv'   --> The file name with extension\n",
    "print(p.stem)    # 'olist_orders'       --> The file name without the extension\n",
    "print(p.suffix)  # '.csv'               --> The file extension (including the dot)\n",
    "print(p.parent)  # WindowsPath('C:/Data/Raw') --> The directory path containing the file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c244a18",
   "metadata": {},
   "source": [
    "#### Encoding / decoding (text ↔ bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e0055736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "नमस्ते, TechConvos!\n",
      "b'\\xe0\\xa4\\xa8\\xe0\\xa4\\xae\\xe0\\xa4\\xb8\\xe0\\xa5\\x8d\\xe0\\xa4\\xa4\\xe0\\xa5\\x87, TechConvos!'\n",
      "नमस्ते, TechConvos!\n"
     ]
    }
   ],
   "source": [
    "data = \"नमस्ते, TechConvos!\"       # Original string containing Unicode characters (Hindi + English)\n",
    "\n",
    "b = data.encode(\"utf-8\")           # Convert the string into bytes using UTF-8 encoding\n",
    "                                  # Bytes are necessary for writing data to disk or sending over a network\n",
    "\n",
    "txt = b.decode(\"utf-8\")            # Convert the bytes back to a string using UTF-8 decoding\n",
    "                                  # This restores the original text from the bytes\n",
    "\n",
    "# Note:\n",
    "# Always specify the encoding (like 'utf-8') when reading/writing files or streams,\n",
    "# especially when sharing data between different systems,\n",
    "# to avoid corruption or misinterpretation of characters.\n",
    "\n",
    "\n",
    "print(data)    # Prints: नमस्ते, TechConvos!\n",
    "print(b)       # Prints: b'\\xe0\\xa4\\xa8\\xe0\\xa\\\n",
    "         #             4\\xae\\xe0\\xa4\\xb8\\xe0\\xa4\\xa4\\xe0\\xa5\\x87, TechConvos!'\n",
    "print(txt)     # Prints: नमस्ते, TechConvos!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579de496",
   "metadata": {},
   "source": [
    "#### Regex (for advanced splitting/parsing)\n",
    "\n",
    "Use when simple split is not enough (multiple delimiters, patterns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3462a9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '42', 'name ': ' Dhiraj Mishra', 'role': 'Team Lead'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"id=42; name = Dhiraj   Mishra ; role=Team Lead\"\n",
    "\n",
    "# Clean and split\n",
    "clean_text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "parts = re.split(r\"\\s*;\\s*\", clean_text)\n",
    "\n",
    "# Optional: turn into dict\n",
    "data = dict(part.strip().split(\"=\", 1) for part in parts)\n",
    "\n",
    "# Print the final dictionary\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164b935b",
   "metadata": {},
   "source": [
    "### **_Practice tasks (strings_**)\n",
    "\n",
    "Splitter clinic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fe053058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized_txt : > Dhiraj Mishra|Team Lead|Mastek\n",
      "Split Text:> ['Dhiraj Mishra', 'Team Lead', 'Mastek']\n"
     ]
    }
   ],
   "source": [
    "# Task: Normalize to \"Dhiraj Mishra|Team Lead|Mastek\" and then get [\"Dhiraj Mishra\",\"Team Lead\",\"Mastek\"]\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "raw_txt = \" Dhiraj Mishra | Team Lead | Mastek \"\n",
    "\n",
    "# Step 1: Trim leading/trailing spaces\n",
    "trim_space = raw_txt.strip()\n",
    "\n",
    "# Step 2: Replace all ' | ' (with optional spaces) with '|'\n",
    "replace_txt = re.sub(r'\\s*\\|\\s*', '|', trim_space)\n",
    "\n",
    "# Step 3: Split into parts and strip individual items (optional but good)\n",
    "split_txt = [item.strip() for item in replace_txt.split('|')]\n",
    "\n",
    "# Output\n",
    "print(\"Normalized_txt : >\", replace_txt)\n",
    "print(\"Split Text:>\", split_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8930069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "example.com\n"
     ]
    }
   ],
   "source": [
    "# Email validator: build is_valid_email(s) (basic rules) and email_domain(s) returning domain in lowercase.\n",
    "import re\n",
    "\n",
    "def is_valid_email(s):\n",
    "    pattern = r'^[A-Za-z0-9._-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}$'\n",
    "    return bool(re.match(pattern,s))\n",
    "\n",
    "def email_domain(s):\n",
    "    if not is_valid_email(s):\n",
    "        raise ValueError(\"Invalid Email Address\")\n",
    "    return s.split('@')[1].lower()\n",
    "\n",
    "# output\n",
    "print(is_valid_email(\"Test.User@example.com\"))     # True\n",
    "print(is_valid_email(\"bademail@@example.com\"))     # False\n",
    "print(email_domain(\"Test.User@Example.COM\"))        # \"example.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "251e5d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'sales', 'date': '2025-08-26', 'tag': 'final', 'ext': 'csv'}\n"
     ]
    }
   ],
   "source": [
    "# Filename parts: from \"sales.2025-08-26.final.csv\" \n",
    "# return: name=sales, date=2025-08-26, tag=final, ext=csv. Prefer Path + rsplit. \n",
    " \n",
    "from pathlib import Path  # Import Path from pathlib for easy filename handling\n",
    "\n",
    "file_name = \"sales.2025-08-26.final.csv\"   # ✅ Global variable — declared before use\n",
    "\n",
    "def parse_filename(filename):   # ✅ Function defined before calling\n",
    "    path = Path(filename)       # Convert the filename to a Path object\n",
    "    stem = path.stem            # Get the filename without the extension (e.g., \"sales.2025-08-26.final\")\n",
    "    ext = path.suffix[1:]       # Get the extension and remove the leading dot (e.g., \"csv\")\n",
    "\n",
    "    # Split the stem from the right into exactly 3 parts: name, date, tag\n",
    "    parts = stem.rsplit('.', 2)\n",
    "\n",
    "    # If the filename doesn't match the expected format, raise an error\n",
    "    if len(parts) != 3:\n",
    "        raise ValueError(\"Filename format must be: name.date.tag.ext\")\n",
    "\n",
    "    # Unpack the parts into name, date, and tag\n",
    "    name, date, tag = parts\n",
    "\n",
    "    # Return the extracted parts as a dictionary\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"date\": date,\n",
    "        \"tag\": tag,\n",
    "        \"ext\": ext\n",
    "    }\n",
    "\n",
    "# Call the function and store the result\n",
    "result = parse_filename(file_name)  # ✅ Called after variable and function are both defined\n",
    "\n",
    "# Print the result\n",
    "print(result)                        # ✅ Uses result correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1998dab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words by frequency:\n",
      "\n",
      "the             : 3\n",
      "data            : 3\n",
      "more            : 3\n",
      "you             : 2\n",
      "in              : 1\n",
      "age             : 1\n",
      "of              : 1\n",
      "information     : 1\n",
      "is              : 1\n",
      "everything      : 1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "text = \"\"\"\n",
    "In the age of information, data is everything. The more data you have,\n",
    "the better decisions you can make. But with more data comes more responsibility.\n",
    "\"\"\"\n",
    "\n",
    "def top_10_words(paragraph):\n",
    "    # 1. Case-fold the paragraph (Unicode-aware lowercase)\n",
    "    paragraph = paragraph.casefold()\n",
    "\n",
    "    # 2. Remove punctuation (keep only letters, numbers, underscores, and spaces)\n",
    "    paragraph = re.sub(r'[^\\w\\s]', '', paragraph)\n",
    "\n",
    "    # 3. Split paragraph into words on whitespace\n",
    "    words = paragraph.split()\n",
    "\n",
    "    # 4. Count frequencies of each word\n",
    "    word_counts = Counter(words)\n",
    "\n",
    "    # 5. Return top 10 most common words as (word, count) tuples\n",
    "    return word_counts.most_common(10)\n",
    "\n",
    "# Call the function with the input text\n",
    "result = top_10_words(text)\n",
    "\n",
    "# Nicely print the results\n",
    "print(\"Top 10 words by frequency:\\n\")\n",
    "for word, count in result:\n",
    "    print(f\"{word.ljust(15)} : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93e8c3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Quick Brown Fox Jumps Over the Lazy Dog\n",
      "A Tale of Two Cities and a Revolution\n",
      "War and Peace: the Story of Us\n"
     ]
    }
   ],
   "source": [
    "# Smart title case: title‑case but keep small words (“and”, “of”, “the”) lowercase unless at start/end.\n",
    "\n",
    "\n",
    "# ✅ What is \"Smart Title Case\"?\n",
    "\n",
    "# It follows these rules:\n",
    "# Capitalize the first and last words — no matter what they are.\n",
    "# Capitalize all major words — nouns, verbs, adjectives, etc.\n",
    "# Do NOT capitalize short/common words (called \"small words\") like: and, or, but, the, a, an, of, in, on, at, to, for, etc.\n",
    "\n",
    "import re\n",
    "\n",
    "def smart_title_case(title):\n",
    "    small_words = {\n",
    "        'a', 'an', 'and', 'as', 'at', 'but', 'by', 'for', 'if', 'in', 'nor',\n",
    "        'of', 'on', 'or', 'per', 'the', 'to', 'vs', 'via', 'with'\n",
    "    }\n",
    "\n",
    "    # Correct regex to keep words and punctuation\n",
    "    words = re.findall(r'\\b\\w+\\b|\\W+', title.lower())\n",
    "\n",
    "    word_indices = [i for i, w in enumerate(words) if w.isalnum()]\n",
    "    first = word_indices[0]\n",
    "    last = word_indices[-1]\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        if not word.isalnum():\n",
    "            result.append(word)\n",
    "        elif i == first or i == last or word not in small_words:\n",
    "            result.append(word.capitalize())\n",
    "        else:\n",
    "            result.append(word)\n",
    "    \n",
    "    return ''.join(result)\n",
    "\n",
    "\n",
    "# Test cases\n",
    "print(smart_title_case(\"the quick brown fox jumps over the lazy dog\"))\n",
    "print(smart_title_case(\"a tale of two cities and a revolution\"))\n",
    "print(smart_title_case(\"war and peace: the story of us\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49235317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98*****210\n"
     ]
    }
   ],
   "source": [
    "# Masking: mask middle digits of phone \"9876543210\" → \"98*****210\" (handle variable lengths).\n",
    "\n",
    "def mask_phone_number(phone):\n",
    "    # Convert input to string in case it's given as an integer or other type\n",
    "    phone = str(phone)\n",
    "    \n",
    "    # If the phone number is too short (5 digits or fewer), we skip masking\n",
    "    # because there's not enough middle space to hide — just return as-is\n",
    "\n",
    "    if len(phone) <= 5:\n",
    "        return phone\n",
    "\n",
    "    # Extract the first 2 digits (to be shown)\n",
    "    first = phone[:2]\n",
    "\n",
    "    # Extract the last 3 digits (to be shown)\n",
    "    last = phone[-3:]\n",
    "    \n",
    "\n",
    "    # Calculate the number of middle digits to mask with '*'\n",
    "    # Total masked = total length - (2 at start + 3 at end) = len - 5\n",
    "\n",
    "    middle = '*' * (len(phone) -5)\n",
    "\n",
    "    # Concatenate first part + masked part + last part\n",
    "    return first + middle + last\n",
    "\n",
    "print(mask_phone_number(\"9876543210\"))\n",
    "# Output: \"98*****210\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "67eb56d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Alice, your order 12345 ships on .\n"
     ]
    }
   ],
   "source": [
    "# Template fill: with f‑strings or .format, create \"Hello {name}, your order {order_id} ships on {date}.\" safely using defaults when missing.\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def fill_template(template, data):\n",
    "    \"\"\"\n",
    "    Safely fills the template string with values from 'data'.\n",
    "    Missing keys default to an empty string to avoid errors.\n",
    "\n",
    "    Args:\n",
    "        template (str): Template string with placeholders, e.g. \"Hello {name}, your order {order_id} ships on {date}.\"\n",
    "        data (dict): Dictionary with keys and values to fill the template.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted string with placeholders replaced or defaulted.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a defaultdict that returns '' for missing keys\n",
    "    safe_data = defaultdict(str, data)\n",
    "\n",
    "    # Use format_map which accepts a mapping and substitutes missing keys with ''\n",
    "    return template.format_map(safe_data)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "template = \"Hello {name}, your order {order_id} ships on {date}.\"\n",
    "data = {\"name\": \"Alice\", \"order_id\": 12345}  # 'date' key is missing\n",
    "\n",
    "print(fill_template(template, data))\n",
    "# Output: Hello Alice, your order 12345 ships on .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4670cbb",
   "metadata": {},
   "source": [
    "#### Translation & Mapping (str.translate, str.maketrans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5128789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H3ll0w, w0rld\n"
     ]
    }
   ],
   "source": [
    "# Create a translation table that maps certain characters to their replacements\n",
    "# str.maketrans() takes a dictionary where:\n",
    "#   - keys are characters to find in the original string\n",
    "#   - values are characters to replace those keys with\n",
    "table = str.maketrans({\n",
    "    \"a\": \"@\",  # replace 'a' with '@'\n",
    "    \"e\": \"3\",  # replace 'e' with '3'\n",
    "    \"i\": \"1\",  # replace 'i' with '1'\n",
    "    \"o\": \"0\"   # replace 'o' with '0'\n",
    "})\n",
    "\n",
    "# Original string to transform\n",
    "text = \"Hellow, world\"\n",
    "\n",
    "# Use the translate() method of the string to replace characters based on the table\n",
    "# It goes through each character in 'text', and if the character is in 'table',\n",
    "# it replaces it with the mapped character. Otherwise, it keeps the character as is.\n",
    "result = text.translate(table)\n",
    "\n",
    "# result will be: \"H3ll0w, w0rld\"\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de53a027",
   "metadata": {},
   "source": [
    "#### Partitioning (partition, rpartition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b66e6d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protocol (schema): https\n",
      "Separator: ://\n",
      "Rest of URL: openai.com/blog\n"
     ]
    }
   ],
   "source": [
    "url = \"https://openai.com/blog\"  # Define a URL string\n",
    "\n",
    "# Use the partition() method to split the URL at the first occurrence of \"://\"\n",
    "# partition() returns a tuple with three parts:\n",
    "#   1) The part before \"://\"\n",
    "#   2) The separator itself (\"://\")\n",
    "#   3) The part after \"://\"\n",
    "schema, _, rest = url.partition(\"://\")\n",
    "\n",
    "# After this:\n",
    "# schema will hold \"https\"      -> the URL protocol (or scheme)\n",
    "# _ will hold \"://\"             -> the separator itself (ignored by using _)\n",
    "# rest will hold \"openai.com/blog\"  -> the remaining part of the URL (domain + path)\n",
    "\n",
    "# Print the extracted parts to verify\n",
    "print(\"Protocol (schema):\", schema)\n",
    "print(\"Separator:\", _)  # Usually ignored, but printed here for clarity\n",
    "print(\"Rest of URL:\", rest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e48b38",
   "metadata": {},
   "source": [
    "#### Justifying & Padding (ljust, rjust, center, zfill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7b902c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi   \n",
      "   Hi\n",
      "  Hi \n",
      "00042\n"
     ]
    }
   ],
   "source": [
    "# ljust(width) - Left-justify the string (pads right with spaces)\n",
    "print(\"Hi\".ljust(5))   # Output: 'Hi   '\n",
    "\n",
    "# rjust(width) - Right-justify the string (pads left with spaces)\n",
    "print(\"Hi\".rjust(5))   # Output: '   Hi'\n",
    "\n",
    "# center(width) - Center the string (pads both sides with spaces)\n",
    "print(\"Hi\".center(5))  # Output: ' Hi  '\n",
    "\n",
    "# zfill(width) - Pad left with zeros (for numeric strings)\n",
    "print(\"42\".zfill(5))   # Output: '00042'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7797c586",
   "metadata": {},
   "source": [
    "#### Advanced Formatting (format specifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "09c81925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14\n",
      "1,000\n",
      "85%\n"
     ]
    }
   ],
   "source": [
    "pi = 3.14159265\n",
    "\n",
    "# Format pi to 2 decimal places:\n",
    "# {:.2f} means:\n",
    "#   - ':' starts format spec\n",
    "#   - '.2' limits to 2 decimal places\n",
    "#   - 'f' formats as a fixed-point number (float)\n",
    "formatted_pi = f\"{pi:.2f}\"   # Output: '3.14'\n",
    "\n",
    "# Format 1000 with comma as thousands separator and no decimals:\n",
    "# {:,.0f} means:\n",
    "#   - ',' adds commas for thousands\n",
    "#   - '.0' means zero decimal places\n",
    "#   - 'f' fixed-point number formatting\n",
    "formatted_number = f\"{1000:,.0f}\"  # Output: '1,000'\n",
    "\n",
    "# Format 0.85 as a percentage with no decimals:\n",
    "# {:.0%} means:\n",
    "#   - '.' starts precision specifier\n",
    "#   - '0' means zero decimal places\n",
    "#   - '%' multiplies number by 100 and adds '%'\n",
    "formatted_percentage = f\"{0.85:.0%}\"  # Output: '85%'\n",
    "\n",
    "print(formatted_pi)        # 3.14\n",
    "print(formatted_number)    # 1,000\n",
    "print(formatted_percentage) # 85%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee86156",
   "metadata": {},
   "source": [
    "#### Unicode awareness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f560dcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "café\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "# Unicode characters can have multiple representations.\n",
    "# For example, \"é\" can be:\n",
    "# 1. A single composed character (U+00E9, 'é')\n",
    "# 2. A combination of 'e' (U+0065) + an accent (U+0301)\n",
    "\n",
    "# Unicode normalization helps standardize these forms.\n",
    "\n",
    "# 'NFC' (Normalization Form C) composes characters to their combined form\n",
    "normalized_text = unicodedata.normalize(\"NFC\", \"café\")\n",
    "\n",
    "# Here, \"café\" with an 'é' that might be decomposed (e + accent)\n",
    "# is normalized into a single composed character for 'é'.\n",
    "print(normalized_text)  # Output: 'café'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442a8c3e",
   "metadata": {},
   "source": [
    "#### String constants (string module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0befc962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyz\n",
      "0123456789\n",
      "'!' is a punctuation mark.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Get all lowercase ASCII letters\n",
    "print(string.ascii_lowercase)  \n",
    "# Output: 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "# Get all digits\n",
    "print(string.digits)           \n",
    "# Output: '0123456789'\n",
    "\n",
    "# Check if a character is punctuation\n",
    "char = '!'\n",
    "if char in string.punctuation:\n",
    "    print(f\"'{char}' is a punctuation mark.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4678c9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'A' is a letter.\n"
     ]
    }
   ],
   "source": [
    "# Check if a character is a letter, digit, or punctuation\n",
    "\n",
    "import string\n",
    "\n",
    "char = 'A'\n",
    "\n",
    "if char in string.ascii_letters:\n",
    "    print(f\"'{char}' is a letter.\")\n",
    "elif char in string.digits:\n",
    "    print(f\"'{char}' is a digit.\")\n",
    "elif char in string.punctuation:\n",
    "    print(f\"'{char}' is punctuation.\")\n",
    "else:\n",
    "    print(f\"'{char}' is something else.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800207b2",
   "metadata": {},
   "source": [
    "#### Performance hacks (big data ETL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3795e153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123-45-6789 matches\n",
      "987-65-4321 matches\n",
      "invalid does NOT match\n",
      "Extract Transform Load\n",
      "This is a large string built efficiently.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import io\n",
    "\n",
    "# 1. re.compile() - Precompile regex for repeated use\n",
    "# Compiling the regex pattern once saves time when matching many strings,\n",
    "# because Python won't recompile the pattern each time.\n",
    "pattern = re.compile(r'\\d{3}-\\d{2}-\\d{4}')  # Pattern for SSN format: 123-45-6789\n",
    "\n",
    "data = ['123-45-6789', '987-65-4321', 'invalid']\n",
    "for item in data:\n",
    "    if pattern.match(item):\n",
    "        print(f\"{item} matches\")\n",
    "    else:\n",
    "        print(f\"{item} does NOT match\")\n",
    "\n",
    "# 2. str.join() - Faster string concatenation than looping with '+'\n",
    "# When combining many strings, collect them in a list and join once,\n",
    "# instead of concatenating in a loop which creates many intermediate strings.\n",
    "words = ['Extract', 'Transform', 'Load']\n",
    "sentence = ' '.join(words)  # Efficient and fast\n",
    "print(sentence)  # Output: Extract Transform Load\n",
    "\n",
    "# 3. io.StringIO - Efficiently build very large strings\n",
    "# StringIO acts like an in-memory file buffer, allowing multiple writes\n",
    "# without creating new string objects each time.\n",
    "buffer = io.StringIO()\n",
    "buffer.write(\"This \")\n",
    "buffer.write(\"is \")\n",
    "buffer.write(\"a \")\n",
    "buffer.write(\"large string built efficiently.\")\n",
    "result = buffer.getvalue()\n",
    "print(result)\n",
    "buffer.close()  # Close the buffer when done to free resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bde7f2d",
   "metadata": {},
   "source": [
    "#### Suggested Final Practice Task (Capstone for Strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bea5fb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OrderID': 42, 'Name': 'Dhiraj Mishra', 'Email': 'dhiraj@example.com', 'File': {'name': 'report', 'date': '2025-08-26', 'tag': 'final', 'ext': 'csv'}}\n"
     ]
    }
   ],
   "source": [
    "# Importing the re(regular expressions) module:\n",
    "import re    \n",
    "\n",
    "def clean_str(data):\n",
    "    # Step 1: Extract key-value pairs using a regular expression:\n",
    "    pattern = r'(\\w+)\\s*=\\s*([^;]+)'\n",
    "    extracted_data = re.findall(pattern, data)\n",
    "\n",
    "    # Step 2: Clean and organize the data:\n",
    "    result = {}  # initialize an empty dictionary to store the cleaned and structured data\n",
    "\n",
    "    # Looping through the extracted key-value pairs:\n",
    "    for key, value in extracted_data:\n",
    "        # remove any leading or trailing spaces from both the key and the value\n",
    "        key = key.strip()\n",
    "        value = value.strip()\n",
    "\n",
    "        # Handling different types of values (conditional logic):\n",
    "        if key == \"OrderID\":                    # For \"OrderID\", convert it to integer\n",
    "            result[key] = int(value)\n",
    "\n",
    "        # Handling the \"Name\" key:\n",
    "        elif key == \"Name\":                     # For \"Name\", keep the string as it is\n",
    "            result[key] = \" \".join(value.split())\n",
    "        \n",
    "        # For \"Email\", convert to lowercase\n",
    "        elif key == 'Email':\n",
    "            result[key] = value.strip().lower()\n",
    "\n",
    "        # For \"File\", process the file string\n",
    "        elif key == \"file\":\n",
    "            # Use '.' as the delimiter to split file parts\n",
    "            file_parts = value.strip().split('.')\n",
    "            \n",
    "            # Check if we have the expected number of parts (6 parts)\n",
    "            if len(file_parts) == 6:\n",
    "                file_info = {\n",
    "                    \"name\": file_parts[0],\n",
    "                    \"date\": file_parts[1] + '-' + file_parts[2] + '-' + file_parts[3],\n",
    "                    \"tag\": file_parts[4],\n",
    "                    \"ext\": file_parts[5]\n",
    "                }\n",
    "                result[\"File\"] = file_info\n",
    "            else:\n",
    "                print(f\"Error: Unexpected file format in '{value}'\")\n",
    "                # Optional: Set a default or error value for \"File\" in case of unexpected format\n",
    "                result[\"File\"] = None\n",
    "\n",
    "    return result\n",
    "\n",
    "# Input data \n",
    "data = \"   OrderID=  42;  Name= Dhiraj   Mishra ;Email= DHIRAJ@Example.COM; file= report.2025.08.26.final.csv   \"\n",
    "\n",
    "# Process the data\n",
    "output = clean_str(data)\n",
    "\n",
    "# Print the result\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee2c054",
   "metadata": {},
   "source": [
    "#### Process a Batch of Inputs (test function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334bff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'OrderID': 42, 'Name': 'Dhiraj Mishra', 'Email': 'dhiraj@example.com', 'File': {'name': 'report', 'date': '2025-08-26', 'tag': 'final', 'ext': 'csv'}}\n",
      "\n",
      "{'OrderID': 101, 'Name': 'Alice Wonderland', 'Email': 'alice@example.com', 'File': {'name': 'data', 'date': '2024-11-01', 'tag': 'report', 'ext': 'csv'}}\n",
      "\n",
      "{'OrderID': 999, 'Name': 'John Doe', 'Email': 'john@example.com', 'File': {'name': 'sales', 'date': '2023-12-12', 'tag': 'final', 'ext': 'csv'}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = [\n",
    "    \"   OrderID=  42;  Name= Dhiraj   Mishra ;Email= DHIRAJ@Example.COM; file= report.2025.08.26.final.csv   \",\n",
    "    \"   OrderID=  101;  Name= Alice   Wonderland ;Email= ALICE@Example.com; file= data.2024.11.01.report.csv   \",\n",
    "    \"   OrderID=  999;  Name= John Doe ;Email= JOHN@EXAMPLE.COM; file= sales.2023.12.12.final.csv   \"\n",
    "]\n",
    "\n",
    "for data in test_data:\n",
    "    print(clean_str(data))\n",
    "    print()  # To add a blank line between outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51627be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
